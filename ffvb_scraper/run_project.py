# run_simple_scraper.py
import sys
import os
from scrapy.crawler import CrawlerProcess
from scrapy.settings import Settings

def run_ffvb_scraper():
    """Lance le scraper FFVB simplifiÃ© pour export CSV"""
    print("ğŸ SCRAPER FFVB - EXPORT CSV UNIQUEMENT")
    print("=" * 50)
    print("ğŸ¯ Objectif: Extraire les donnÃ©es du site FFVB au format CSV")
    print("ğŸ“ Fichier de sortie: ffvb_data_export.csv")
    print()
    
    # VÃ©rifier qu'on est dans le bon rÃ©pertoire
    if not os.path.exists('ffvb_scraper'):
        print("âŒ RÃ©pertoire ffvb_scraper non trouvÃ©")
        print("ğŸ’¡ Assurez-vous d'Ãªtre dans le rÃ©pertoire parent du projet Scrapy")
        return False
    
    # Ajouter le rÃ©pertoire du projet au PYTHONPATH
    current_dir = os.getcwd()
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # Configuration Scrapy
    settings = Settings()
    settings.setmodule('ffvb_scraper.settings')
    
    # ParamÃ¨tres pour un scraping respectueux
    settings.set('LOG_LEVEL', 'INFO')
    settings.set('DOWNLOAD_DELAY', 3)
    settings.set('ROBOTSTXT_OBEY', True)
    settings.set('CONCURRENT_REQUESTS', 1)
    
    # CrÃ©er le processus crawler
    process = CrawlerProcess(settings)
    
    try:
        # Importer le spider
        from ffvb_scraper.spiders.ffvb_simple_spider import FFVBSimpleSpider
        
        print("ğŸ•·ï¸  DÃ©marrage du scraping...")
        print("â³ Cela peut prendre 2-5 minutes selon la quantitÃ© de donnÃ©es...")
        print("ğŸ“Š Le fichier CSV se remplit en temps rÃ©el")
        print()
        
        # Ajouter le spider et lancer
        process.crawl(FFVBSimpleSpider)
        process.start()  # Bloque jusqu'Ã  la fin
        
        print()
        print("âœ… SCRAPING TERMINÃ‰!")
        print("ğŸ“„ Fichier gÃ©nÃ©rÃ©: ffvb_data_export.csv")
        
        # VÃ©rifier si le fichier existe et donner des stats
        if os.path.exists('ffvb_data_export.csv'):
            with open('ffvb_data_export.csv', 'r', encoding='utf-8') as f:
                line_count = sum(1 for line in f) - 1  # -1 pour l'en-tÃªte
            print(f"ğŸ“ˆ Nombre de lignes extraites: {line_count}")
            print(f"ğŸ“‹ Colonnes disponibles:")
            print("   - type_donnee (Article, Championnat, Resultat_Historique)")
            print("   - titre, date, contenu, equipe_gagnant, position")
            print("   - region, division, categorie, url_source, date_scraping")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Erreur d'import: {e}")
        print("ğŸ’¡ VÃ©rifiez que ffvb_simple_spider.py est dans ffvb_scraper/spiders/")
        return False
    except Exception as e:
        print(f"âŒ Erreur pendant le scraping: {e}")
        return False

def main():
    """Fonction principale"""
    success = run_ffvb_scraper()
    
    if success:
        print()
        print("ğŸ‰ EXPORT RÃ‰USSI!")
        print("ğŸ’¡ Vous pouvez maintenant:")
        print("   1. Ouvrir ffvb_data_export.csv dans Excel/LibreOffice")
        print("   2. Analyser les donnÃ©es avec Python/R")
        print("   3. CrÃ©er vos propres visualisations")
        print()
        print("ğŸ“ˆ Types de donnÃ©es extraites:")
        print("   â€¢ Articles et actualitÃ©s du volleyball franÃ§ais")
        print("   â€¢ RÃ©sultats historiques des championnats")
        print("   â€¢ Classements actuels par division")
        print("   â€¢ Informations gÃ©ographiques (rÃ©gions)")
    else:
        print()
        print("âŒ Ã‰chec de l'export")
        print("ğŸ’¡ VÃ©rifiez la structure du projet et les dÃ©pendances")

if __name__ == "__main__":
    main()