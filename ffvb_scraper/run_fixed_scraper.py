# run_fixed_scraper.py
import sys
import os
from scrapy.crawler import CrawlerProcess

def run_fixed_scraper():
    """Lance le scraper corrigÃ© pour extraire tous les joueurs"""
    print("ğŸ SCRAPER FFVB CORRIGÃ‰ - EXTRACTION DES JOUEURS")
    print("=" * 55)
    print("ğŸ¯ Objectifs:")
    print("   âœ“ Extraire les images CV des joueurs")
    print("   âœ“ Naviguer entre les pages de joueurs") 
    print("   âœ“ Collecter les informations disponibles")
    print("   âœ“ GÃ©rer les URLs encodÃ©es")
    print()
    print("ğŸ“ Fichier gÃ©nÃ©rÃ©: ffvb_players_fixed.csv")
    print()
    
    # Configuration Scrapy optimisÃ©e
    settings = {
        'BOT_NAME': 'ffvb_fixed',
        'ROBOTSTXT_OBEY': True,
        'DOWNLOAD_DELAY': 1.5,  # Plus rapide mais respectueux
        'RANDOMIZE_DOWNLOAD_DELAY': 0.5,
        'LOG_LEVEL': 'INFO',
        'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        
        # Gestion des erreurs
        'RETRY_TIMES': 2,
        'RETRY_HTTP_CODES': [500, 502, 503, 504, 408, 429],
        
        # Performance
        'CONCURRENT_REQUESTS': 2,  # LimitÃ© pour Ãªtre respectueux
        'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
        
        # Pas de caching pour avoir les donnÃ©es fraÃ®ches
        'HTTPCACHE_ENABLED': False,
        
        # Formats de sortie
        'FEEDS': {
            'ffvb_players_detailed.json': {
                'format': 'json',
                'encoding': 'utf8',
                'store_empty': False,
                'indent': 2,
            },
        },
    }
    
    # Ajouter le rÃ©pertoire actuel au PYTHONPATH
    current_dir = os.getcwd()
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    process = CrawlerProcess(settings)
    
    try:
        from ffvb_scraper.spiders.ffvb_fixed_spider import FFVBFixedSpider
        
        print("ğŸ•·ï¸  DÃ©marrage du scraper corrigÃ©...")
        print("â³ Cela peut prendre quelques minutes...")
        print()
        
        process.crawl(FFVBFixedSpider)
        process.start()
        
        print()
        print("âœ… EXTRACTION TERMINÃ‰E!")
        print()
        
        # VÃ©rifier les rÃ©sultats
        if os.path.exists('ffvb_players_fixed.csv'):
            with open('ffvb_players_fixed.csv', 'r', encoding='utf-8') as f:
                lines = sum(1 for line in f) - 1  # -1 pour l'en-tÃªte
            print(f"ğŸ“Š Joueurs trouvÃ©s: {lines}")
            
            # Afficher un aperÃ§u
            with open('ffvb_players_fixed.csv', 'r', encoding='utf-8') as f:
                content = f.read()
                print()
                print("ğŸ“‹ AperÃ§u des donnÃ©es:")
                print(content[:500] + "..." if len(content) > 500 else content)
        
        if os.path.exists('ffvb_players_detailed.json'):
            size = os.path.getsize('ffvb_players_detailed.json')
            print(f"ğŸ“„ Fichier JSON: {size:,} bytes")
        
        print()
        print("ğŸ” PROCHAINES Ã‰TAPES:")
        print("1. VÃ©rifiez ffvb_players_fixed.csv pour les joueurs trouvÃ©s")
        print("2. Si peu de joueurs, le site peut utiliser du JavaScript")
        print("3. ConsidÃ©rez utiliser Selenium pour les pages dynamiques")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Erreur d'import: {e}")
        print("ğŸ’¡ VÃ©rifiez que le fichier spider existe dans le bon rÃ©pertoire")
        return False
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

if __name__ == "__main__":
    run_fixed_scraper()