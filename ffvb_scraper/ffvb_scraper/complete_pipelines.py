# complete_ffvb_pipeline.py
"""
Pipeline complet pour extraction maximale des donn√©es des joueurs FFVB
Combine Scrapy + Selenium + OCR pour r√©cup√©rer toutes les informations possibles
"""

import os
import sys
import time
import json
import csv
import subprocess
from datetime import datetime
from pathlib import Path

class FFVBCompletePipeline:
    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = f"ffvb_extraction_{self.timestamp}"
        self.setup_directories()
        
        self.results = {
            'scrapy_basic': None,
            'scrapy_advanced': None,
            'selenium': None,
            'ocr': None,
            'final_merged': None
        }

    def setup_directories(self):
        """Cr√©e les r√©pertoires de travail"""
        Path(self.output_dir).mkdir(exist_ok=True)
        Path(f"{self.output_dir}/logs").mkdir(exist_ok=True)
        Path(f"{self.output_dir}/raw_data").mkdir(exist_ok=True)
        Path(f"{self.output_dir}/processed").mkdir(exist_ok=True)
        
        print(f"üìÅ R√©pertoire de travail: {self.output_dir}")

    def run_complete_extraction(self):
        """Lance le pipeline complet d'extraction"""
        print("üèê PIPELINE COMPLET FFVB - EXTRACTION MAXIMALE")
        print("=" * 60)
        print(f"üïê D√©but: {datetime.now().strftime('%H:%M:%S')}")
        print()
        
        steps = [
            ("Scrapy Basique", self.run_scrapy_basic),
            ("Scrapy Avanc√©", self.run_scrapy_advanced),
            ("Selenium (si n√©cessaire)", self.run_selenium_if_needed),
            ("OCR Images CV", self.run_ocr_extraction),
            ("Fusion des donn√©es", self.merge_all_data),
            ("Rapport final", self.generate_final_report)
        ]
        
        for step_name, step_func in steps:
            print(f"\nüîÑ √âTAPE: {step_name}")
            print("-" * 40)
            
            try:
                start_time = time.time()
                success = step_func()
                elapsed = time.time() - start_time
                
                if success:
                    print(f"‚úÖ {step_name} termin√© en {elapsed:.1f}s")
                else:
                    print(f"‚ö†Ô∏è {step_name} partiellement r√©ussi")
                    
            except Exception as e:
                print(f"‚ùå Erreur {step_name}: {e}")
                # Continuer malgr√© l'erreur
        
        print(f"\nüéâ PIPELINE TERMIN√â - {datetime.now().strftime('%H:%M:%S')}")
        print(f"üìÅ R√©sultats dans: {self.output_dir}")

    def run_scrapy_basic(self):
        """Lance le scraper Scrapy basique"""
        try:
            # Utiliser le scraper corrig√© cr√©√© pr√©c√©demment
            from ffvb_scraper.spiders.ffvb_fixed_spider import FFVBFixedSpider
            from scrapy.crawler import CrawlerProcess
            
            settings = {
                'LOG_LEVEL': 'WARNING',
                'FEEDS': {
                    f'{self.output_dir}/raw_data/scrapy_basic.json': {
                        'format': 'json',
                        'encoding': 'utf8'
                    }
                }
            }
            
            process = CrawlerProcess(settings)
            process.crawl(FFVBFixedSpider)
            process.start()
            
            # V√©rifier r√©sultats
            basic_file = f'{self.output_dir}/raw_data/scrapy_basic.json'
            if os.path.exists(basic_file):
                with open(basic_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.results['scrapy_basic'] = len(data) if isinstance(data, list) else 1
                print(f"üìä Scrapy basique: {self.results['scrapy_basic']} joueur(s)")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur Scrapy basique: {e}")
            return False

    def run_scrapy_advanced(self):
        """Lance le scraper Scrapy avanc√©"""
        try:
            from ffvb_scraper.spiders.ffvb_advanced_player_scraper import FFVBAdvancedPlayerSpider
            from scrapy.crawler import CrawlerProcess
            
            settings = {
                'LOG_LEVEL': 'WARNING',
                'DOWNLOAD_DELAY': 2,
                'FEEDS': {
                    f'{self.output_dir}/raw_data/scrapy_advanced.json': {
                        'format': 'json',
                        'encoding': 'utf8'
                    }
                }
            }
            
            process = CrawlerProcess(settings)
            process.crawl(FFVBAdvancedPlayerSpider)
            process.start()
            
            # V√©rifier r√©sultats
            advanced_file = f'{self.output_dir}/raw_data/scrapy_advanced.json'
            if os.path.exists(advanced_file):
                with open(advanced_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.results['scrapy_advanced'] = len(data) if isinstance(data, list) else 1
                print(f"üìä Scrapy avanc√©: {self.results['scrapy_advanced']} joueur(s)")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur Scrapy avanc√©: {e}")
            return False

    def run_selenium_if_needed(self):
        """Lance Selenium si Scrapy n'a pas donn√© assez de r√©sultats"""
        scrapy_results = (self.results.get('scrapy_basic', 0) + 
                         self.results.get('scrapy_advanced', 0))
        
        if scrapy_results >= 10:  # Seuil acceptable
            print("‚úÖ Scrapy a donn√© suffisamment de r√©sultats, Selenium non n√©cessaire")
            return True
        
        print(f"‚ö†Ô∏è Scrapy: seulement {scrapy_results} joueurs, lancement Selenium...")
        
        try:
            from selenium_ffvb_scraper import FFVBSeleniumScraper
            
            scraper = FFVBSeleniumScraper()
            scraper.scrape_players()
            
            # D√©placer le fichier dans notre r√©pertoire
            if os.path.exists('ffvb_players_selenium.csv'):
                import shutil
                shutil.move('ffvb_players_selenium.csv', 
                           f'{self.output_dir}/raw_data/selenium_results.csv')
                
                # Compter les r√©sultats
                with open(f'{self.output_dir}/raw_data/selenium_results.csv', 'r', encoding='utf-8') as f:
                    self.results['selenium'] = sum(1 for line in f) - 1  # -1 pour header
                
                print(f"üìä Selenium: {self.results['selenium']} joueur(s)")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur Selenium: {e}")
            return False

    def run_ocr_extraction(self):
        """Lance l'extraction OCR des images CV"""
        try:
            # V√©rifier qu'on a des donn√©es de base
            base_files = [
                f'{self.output_dir}/raw_data/scrapy_basic.json',
                f'{self.output_dir}/raw_data/scrapy_advanced.json',
                f'{self.output_dir}/raw_data/selenium_results.csv'
            ]
            
            players_with_images = []
            
            # Collecter toutes les URLs d'images
            for file_path in base_files:
                if os.path.exists(file_path):
                    players_with_images.extend(self.extract_image_urls(file_path))
            
            if not players_with_images:
                print("‚ö†Ô∏è Aucune image CV trouv√©e pour OCR")
                return False
            
            print(f"üñºÔ∏è {len(players_with_images)} image(s) CV √† traiter")
            
            # Lancer OCR personnalis√©
            ocr_results = []
            
            for i, player_data in enumerate(players_with_images, 1):
                print(f"   [{i}/{len(players_with_images)}] OCR: {player_data.get('nom', 'N/A')}")
                
                try:
                    ocr_data = self.process_single_image_ocr(player_data)
                    if ocr_data:
                        ocr_results.append(ocr_data)
                        
                except Exception as e:
                    print(f"      ‚ùå Erreur OCR: {e}")
            
            # Sauvegarder r√©sultats OCR
            ocr_file = f'{self.output_dir}/raw_data/ocr_results.json'
            with open(ocr_file, 'w', encoding='utf-8') as f:
                json.dump(ocr_results, f, ensure_ascii=False, indent=2)
            
            self.results['ocr'] = len(ocr_results)
            print(f"üìä OCR: {self.results['ocr']} image(s) trait√©e(s)")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur OCR global: {e}")
            return False

    def extract_image_urls(self, file_path):
        """Extrait les URLs d'images depuis un fichier de donn√©es"""
        players = []
        
        try:
            if file_path.endswith('.json'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                if isinstance(data, list):
                    for item in data:
                        if item.get('url_cv_image'):
                            players.append({
                                'nom': item.get('nom_joueur', ''),
                                'numero': item.get('numero', ''),
                                'image_url': item.get('url_cv_image', '')
                            })
            
            elif file_path.endswith('.csv'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if row.get('url_cv_image'):
                            players.append({
                                'nom': row.get('nom_joueur', ''),
                                'numero': row.get('numero', ''),
                                'image_url': row.get('url_cv_image', '')
                            })
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lecture {file_path}: {e}")
        
        return players

    def process_single_image_ocr(self, player_data):
        """Traite une seule image avec OCR"""
        try:
            import requests
            from PIL import Image
            import pytesseract
            import cv2
            import numpy as np
            from io import BytesIO
            import re
            
            # Construire URL compl√®te
            image_url = player_data['image_url']
            if image_url.startswith('/'):
                full_url = f"http://www.ffvb.org{image_url}"
            else:
                full_url = image_url
            
            # T√©l√©charger image
            response = requests.get(full_url, timeout=10)
            response.raise_for_status()
            
            # Traiter avec OCR
            image = Image.open(BytesIO(response.content))
            
            # Preprocessing simple
            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)
            
            # OCR
            text = pytesseract.image_to_string(gray, config='--psm 6 -l fra')
            
            if not text.strip():
                return None
            
            # Parser le texte pour extraire donn√©es
            extracted_data = {
                'nom_joueur': player_data['nom'],
                'numero': player_data['numero'],
                'image_url': full_url,
                'texte_ocr': text.strip(),
                'date_extraction': datetime.now().isoformat()
            }
            
            # Extraction de donn√©es sp√©cifiques
            patterns = {
                'poste': r'(?:poste|position)[\s:]+([^,\n\r]+)',
                'taille': r'(?:taille)[\s:]*(\d{1,3})(?:\s*cm)?',
                'poids': r'(?:poids)[\s:]*(\d{2,3})(?:\s*kg)?',
                'age': r'(?:√¢ge|age)[\s:]*(\d{1,2})',
                'club': r'(?:club|√©quipe)[\s:]+([^,\n\r]+)'
            }
            
            for field, pattern in patterns.items():
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    extracted_data[field] = match.group(1).strip()
            
            return extracted_data
            
        except Exception as e:
            print(f"      ‚ùå Erreur traitement image: {e}")
            return None

    def merge_all_data(self):
        """Fusionne toutes les donn√©es collect√©es"""
        print("üîÑ Fusion de toutes les sources de donn√©es...")
        
        try:
            merged_players = {}
            
            # Sources de donn√©es
            sources = {
                'scrapy_basic': f'{self.output_dir}/raw_data/scrapy_basic.json',
                'scrapy_advanced': f'{self.output_dir}/raw_data/scrapy_advanced.json',
                'selenium': f'{self.output_dir}/raw_data/selenium_results.csv',
                'ocr': f'{self.output_dir}/raw_data/ocr_results.json'
            }
            
            # Charger et fusionner chaque source
            for source_name, file_path in sources.items():
                if os.path.exists(file_path):
                    players = self.load_players_from_file(file_path)
                    print(f"   üìä {source_name}: {len(players)} entr√©e(s)")
                    
                    for player in players:
                        player_key = self.get_player_key(player)
                        
                        if player_key not in merged_players:
                            merged_players[player_key] = {
                                'sources': [],
                                'data': {}
                            }
                        
                        # Ajouter la source
                        merged_players[player_key]['sources'].append(source_name)
                        
                        # Fusionner les donn√©es (priorit√© aux donn√©es les plus compl√®tes)
                        for key, value in player.items():
                            if value and value.strip():  # Seulement si non vide
                                existing = merged_players[player_key]['data'].get(key)
                                if not existing or len(str(value)) > len(str(existing)):
                                    merged_players[player_key]['data'][key] = value
            
            # Convertir en liste
            final_players = []
            for player_key, player_info in merged_players.items():
                player_data = player_info['data']
                player_data['sources_fusion'] = ' + '.join(player_info['sources'])
                player_data['score_completude'] = self.calculate_completeness_score(player_data)
                final_players.append(player_data)
            
            # Trier par score de compl√©tude
            final_players.sort(key=lambda x: x.get('score_completude', 0), reverse=True)
            
            # Sauvegarder r√©sultat final
            final_file = f'{self.output_dir}/processed/ffvb_players_final.json'
            with open(final_file, 'w', encoding='utf-8') as f:
                json.dump(final_players, f, ensure_ascii=False, indent=2)
            
            # Sauvegarder aussi en CSV
            self.save_final_csv(final_players)
            
            self.results['final_merged'] = len(final_players)
            print(f"‚úÖ Fusion termin√©e: {len(final_players)} joueur(s) uniques")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur fusion: {e}")
            return False

    def load_players_from_file(self, file_path):
        """Charge les joueurs depuis un fichier"""
        players = []
        
        try:
            if file_path.endswith('.json'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        players = data
                    else:
                        players = [data]
            
            elif file_path.endswith('.csv'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    players = list(reader)
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur chargement {file_path}: {e}")
        
        return players

    def get_player_key(self, player):
        """G√©n√®re une cl√© unique pour identifier un joueur"""
        nom = player.get('nom_joueur', '').strip().lower()
        numero = player.get('numero', '').strip()
        
        if nom and numero:
            return f"{nom}_{numero}"
        elif nom:
            return nom
        else:
            return f"unknown_{hash(str(player)) % 10000}"

    def calculate_completeness_score(self, player_data):
        """Calcule un score de compl√©tude des donn√©es"""
        important_fields = [
            'nom_joueur', 'numero', 'poste', 'taille', 'poids', 'age',
            'club_actuel', 'selections', 'matches_joues', 'url_cv_image'
        ]
        
        score = 0
        for field in important_fields:
            if player_data.get(field, '').strip():
                score += 1
        
        return (score / len(important_fields)) * 100

    def save_final_csv(self, players):
        """Sauvegarde le fichier CSV final"""
        csv_file = f'{self.output_dir}/processed/ffvb_players_final.csv'
        
        if not players:
            return
        
        # Obtenir tous les champs possibles
        all_fields = set()
        for player in players:
            all_fields.update(player.keys())
        
        # Ordonner les champs
        ordered_fields = [
            'nom_joueur', 'numero', 'poste', 'taille', 'poids', 'age',
            'club_actuel', 'selections', 'matches_joues', 'victoires', 'defaites',
            'url_cv_image', 'sources_fusion', 'score_completude'
        ]
        
        # Ajouter les champs restants
        remaining_fields = sorted(all_fields - set(ordered_fields))
        final_fields = ordered_fields + remaining_fields
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=final_fields)
            writer.writeheader()
            writer.writerows(players)

    def generate_final_report(self):
        """G√©n√®re le rapport final"""
        print("üìã G√©n√©ration du rapport final...")
        
        try:
            report_file = f'{self.output_dir}/RAPPORT_FINAL.txt'
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("üèê RAPPORT FINAL - EXTRACTION FFVB\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"üìÖ Date: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
                f.write(f"üìÅ R√©pertoire: {self.output_dir}\n\n")
                
                f.write("üìä R√âSULTATS PAR M√âTHODE:\n")
                for method, count in self.results.items():
                    if count is not None:
                        f.write(f"   {method}: {count} joueur(s)\n")
                
                f.write(f"\nüéØ TOTAL FINAL: {self.results.get('final_merged', 0)} joueur(s) uniques\n\n")
                
                # Analyse des fichiers g√©n√©r√©s
                f.write("üìÅ FICHIERS G√âN√âR√âS:\n")
                for root, dirs, files in os.walk(self.output_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        size = os.path.getsize(file_path)
                        rel_path = os.path.relpath(file_path, self.output_dir)
                        f.write(f"   {rel_path}: {size:,} bytes\n")
                
                f.write("\n‚úÖ EXTRACTION TERMIN√âE AVEC SUCC√àS!")
            
            print(f"üìÑ Rapport sauvegard√©: {report_file}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur rapport: {e}")
            return False

def main():
    """Fonction principale"""
    print("üöÄ PIPELINE COMPLET FFVB")
    print("Extraction maximale des donn√©es des joueurs")
    print()
    
    # V√©rifier les d√©pendances
    missing_deps = check_dependencies()
    if missing_deps:
        print("‚ùå D√©pendances manquantes:")
        for dep in missing_deps:
            print(f"   - {dep}")
        print("\nüì¶ Installez avec: pip install " + " ".join(missing_deps))
        return False
    
    try:
        pipeline = FFVBCompletePipeline()
        pipeline.run_complete_extraction()
        
        print(f"\nüéâ SUCC√àS! Consultez le r√©pertoire: {pipeline.output_dir}")
        return True
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Arr√™t demand√© par l'utilisateur")
        return False
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        return False

def check_dependencies():
    """V√©rifie les d√©pendances requises"""
    required = {
        'scrapy': 'scrapy',
        'selenium': 'selenium',
        'PIL': 'pillow',
        'cv2': 'opencv-python',
        'pytesseract': 'pytesseract',
        'requests': 'requests'
    }
    
    missing = []
    for module, package in required.items():
        try:
            __import__(module)
        except ImportError:
            missing.append(package)
    
    return missing

if __name__ == "__main__":
    main()